{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Reshape, Flatten\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.layers.convolutional import Convolution2D, Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from functools import partial\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "DISCRIMINATOR_UPDATES_ITERS = 5  # number of discriminator updates per generator update\n",
    "GP_WEIGHT = 10\n",
    "EPOCHS_NUM = 100\n",
    "\n",
    "OUTPUT_DIR = os.path.join(\"results\", \"conv_wgan_gp_with_swae_decoder\") \n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "CHECKPOINT_DIR = os.path.join(\"saved_models\", \"conv_wgan_gp_with_swae_decoder\", \"checkpoints\") \n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_loss(y_true, y_pred, averaged_samples, gp_weight):\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    gradients_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    gradient_penalty = gp_weight * K.square(1 - gradients_l2_norm)\n",
    "    return K.mean(gradient_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def make_generator():\n",
    "    model = load_model(r\"C:\\Users\\User\\Desktop\\ganfasttraining\\saved_models\\convolutional_swae\\checkpoints\\Epoch_90\\generator_model.h5\")\n",
    "    return model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=100))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dense(128 * 7 * 7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Reshape((7, 7, 128), input_shape=(128 * 7 * 7,)))\n",
    "    model.add(Conv2DTranspose(128, (5, 5), strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Convolution2D(64, (5, 5), padding=\"same\"))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv2DTranspose(64, (5, 5), strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Convolution2D(1, (5, 5), padding=\"same\", activation=\"tanh\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(64, (5, 5), padding=\"same\", input_shape=(28, 28, 1)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Convolution2D(128, (5, 5), kernel_initializer=\"he_normal\", strides=[2, 2]))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Convolution2D(128, (5, 5), kernel_initializer=\"he_normal\", strides=[2, 2], padding=\"same\"))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, kernel_initializer=\"he_normal\"))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dense(1, kernel_initializer=\"he_normal\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_images(image_stack):\n",
    "    assert len(image_stack.shape) == 3\n",
    "    image_list = [image_stack[i, :, :] for i in range(image_stack.shape[0])]\n",
    "    tiled_images = np.concatenate(image_list, axis=1)\n",
    "    return tiled_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(_Merge):\n",
    "    def _merge_function(self, inputs):\n",
    "        weights = K.random_normal((BATCH_SIZE, 1, 1, 1))\n",
    "        return (weights * inputs[0]) + ((1 - weights) * inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def save_predicted_images(generator_model, output_dir, epoch):\n",
    "    test_image_stack = generator_model.predict(np.random.normal(size=(20, 100)))\n",
    "    test_image_stack = (test_image_stack * 127.5) + 127.5\n",
    "    test_image_stack = np.squeeze(np.round(test_image_stack).astype(np.uint8))\n",
    "    tiled_output = tile_images(test_image_stack)\n",
    "    tiled_output = Image.fromarray(tiled_output, mode='L')  # L specifies greyscale\n",
    "    outfile = os.path.join(output_dir, 'epoch_{}.png'.format(epoch))\n",
    "    tiled_output.save(outfile)\n",
    "    \n",
    "def save_generator_model(generator_model, checkpoint_dir, epoch, frechet_distance):\n",
    "    dir_path = os.path.join(checkpoint_dir, \"Epoch_\" + str(epoch))\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "        \n",
    "    fd_json = {\"frechet_distance\": frechet_distance}\n",
    "    with open(os.path.join(dir_path, \"frechet_distance.json\"), \"w\") as f:        \n",
    "        json.dump(fd_json, f, indent=4)\n",
    "    \n",
    "    generator_model.save(os.path.join(dir_path, \"generator_model.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we load the image data, reshape it and normalize it to the range [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = np.concatenate((x_train, x_test), axis=0)\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "div_coeff = 5 / 6\n",
    "train_num = int(len(x_train) * div_coeff)\n",
    "_x_train, x_fid_test = x_train[:train_num - 1], x_train[train_num:]\n",
    "x_train = _x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "generator = make_generator()\n",
    "discriminator = make_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "SWAEDecoder (Model)          (None, 28, 28, 1)         3901569   \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 5336961   \n",
      "=================================================================\n",
      "Total params: 9,238,530\n",
      "Trainable params: 3,892,097\n",
      "Non-trainable params: 5,346,433\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in discriminator.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "discriminator.trainable = False\n",
    "\n",
    "generator_input = Input(shape=(100,))\n",
    "generator_layers = generator(generator_input)\n",
    "discriminator_layers_for_generator = discriminator(generator_layers)\n",
    "generator_model = Model(inputs=[generator_input], outputs=[discriminator_layers_for_generator])\n",
    "\n",
    "# We use the Adam paramaters from Gulrajani et al.\n",
    "generator_model.compile(optimizer=Adam(0.0001, beta_1=0.5, beta_2=0.9), loss=wasserstein_loss)\n",
    "generator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in discriminator.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "for layer in generator.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "discriminator.trainable = True\n",
    "generator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "SWAEDecoder (Model)             (None, 28, 28, 1)    3901569     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "random_weighted_average_1 (Rand (None, 28, 28, 1)    0           input_2[0][0]                    \n",
      "                                                                 SWAEDecoder[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 1)            5336961     SWAEDecoder[2][0]                \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 random_weighted_average_1[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 9,238,530\n",
      "Trainable params: 5,336,961\n",
      "Non-trainable params: 3,901,569\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# The discriminator_model is more complex. It takes both real image samples and random\n",
    "# noise seeds as input. The noise seed is run through the generator model to get\n",
    "# generated images. Both real and generated images are then run through the discriminator.\n",
    "real_samples = Input(shape=x_train.shape[1:])\n",
    "generator_input_for_discriminator = Input(shape=(100,))\n",
    "generated_samples_for_discriminator = generator(generator_input_for_discriminator)\n",
    "discriminator_output_from_generator = discriminator(generated_samples_for_discriminator)\n",
    "discriminator_output_from_real_samples = discriminator(real_samples)\n",
    "\n",
    "# We also need to generate weighted-averages of real and generated samples,\n",
    "# to use for the gradient norm penalty.\n",
    "averaged_samples = RandomWeightedAverage()([real_samples, generated_samples_for_discriminator])\n",
    "# We then run these samples through the discriminator as well. Note that we never\n",
    "# really use the discriminator output for these samples - we're only running them to\n",
    "# get the gradient norm for the gradient penalty loss.\n",
    "averaged_samples_out = discriminator(averaged_samples)\n",
    "\n",
    "# The gradient penalty loss function requires the input averaged samples to get\n",
    "# gradients. However, Keras loss functions can only have two arguments, y_true and\n",
    "# y_pred. We get around this by making a partial() of the function with the averaged samples here.\n",
    "partial_gp_loss = partial(gp_loss, averaged_samples=averaged_samples, gp_weight=GP_WEIGHT)\n",
    "# Functions need names or Keras will throw an error\n",
    "partial_gp_loss.__name__ = 'gradient_penalty'\n",
    "\n",
    "# Keras requires that inputs and outputs have the same number of samples. This is why\n",
    "# we didn't concatenate the real samples and generated samples before passing them to\n",
    "# the discriminator: If we had, it would create an output with 2 * BATCH_SIZE samples,\n",
    "# while the output of the \"averaged\" samples for gradient penalty would have only BATCH_SIZE samples.\n",
    "\n",
    "# If we don't concatenate the real and generated samples, however, we get three\n",
    "# outputs: One of the generated samples, one of the real samples, and one of the\n",
    "# averaged samples, all of size BATCH_SIZE.\n",
    "discriminator_model = Model(inputs=[real_samples, generator_input_for_discriminator],\n",
    "                            outputs=[discriminator_output_from_real_samples,\n",
    "                                     discriminator_output_from_generator,\n",
    "                                     averaged_samples_out])\n",
    "# We use the Adam paramaters from Gulrajani et al. We use the Wasserstein loss for both\n",
    "# the real and generated samples, and the gradient penalty loss for the averaged samples\n",
    "discriminator_model.compile(optimizer=Adam(0.0001, beta_1=0.5, beta_2=0.9),\n",
    "                            loss=[wasserstein_loss,\n",
    "                                  wasserstein_loss,\n",
    "                                  partial_gp_loss])\n",
    "discriminator_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow_gan\\python\\estimator\\tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sys import stdout\n",
    "from collections import namedtuple\n",
    "from tensorflow_gan.examples.mnist import util\n",
    "\n",
    "\n",
    "# We make three label vectors for training. positive_y is the label vector for real\n",
    "# samples, with value 1. negative_y is the label vector for generated samples, with\n",
    "# value -1. The dummy_y vector is passed to the gradient_penalty loss function and is not used.\n",
    "positive_y = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n",
    "negative_y = -positive_y\n",
    "dummy_y = np.zeros((BATCH_SIZE, 1), dtype=np.float32)\n",
    "\n",
    "discriminator_loss = []\n",
    "generator_loss = []\n",
    "\n",
    "n_batches = int(x_train.shape[0] // (BATCH_SIZE * DISCRIMINATOR_UPDATES_ITERS))\n",
    "# print(\"Number of epochs: \", EPOCHS_NUM)\n",
    "# print(\"Number of batches: \", n_batches)\n",
    "\n",
    "epoch = 1\n",
    "num_of_good_epochs = 0\n",
    "\n",
    "frechet_distance_edges = [10, 7, 3, 1, 0.5, 0.1, 0.05, 0.01]\n",
    "frechet_distance_checkpoints = []\n",
    "FDCheckpoint = namedtuple(\"FDCheckpoint\", [\"dist\"])\n",
    "for edge in frechet_distance_edges:\n",
    "    frechet_distance_checkpoints.append(FDCheckpoint(dist=edge))\n",
    "    \n",
    "x_fid_test = tf.convert_to_tensor(x_fid_test, dtype=tf.float32)\n",
    "    \n",
    "while True:\n",
    "#for epoch in range(EPOCHS_NUM):\n",
    "    np.random.shuffle(x_train)\n",
    "    minibatches_size = BATCH_SIZE * DISCRIMINATOR_UPDATES_ITERS\n",
    "    for i in range(n_batches):\n",
    "        discriminator_minibatches = x_train[i * minibatches_size: (i + 1) * minibatches_size]\n",
    "        for j in range(DISCRIMINATOR_UPDATES_ITERS):\n",
    "            image_batch = discriminator_minibatches[j * BATCH_SIZE: (j + 1) * BATCH_SIZE]\n",
    "            noise = np.random.normal(size=(BATCH_SIZE, 100))\n",
    "            discriminator_loss.append(\n",
    "                discriminator_model.train_on_batch([image_batch, noise], [positive_y, negative_y, dummy_y]))\n",
    "            \n",
    "        generator_loss.append(generator_model.train_on_batch(np.random.normal(size=(BATCH_SIZE, 100)), positive_y))\n",
    "        \n",
    "        stdout.write(\"\\rEpoch: [%d], Batch: [%d/%d], D_Loss: %.4f, G_Loss: %.4f\" %\n",
    "                     (epoch, i, n_batches, discriminator_loss[-1][-1], generator_loss[-1]))\n",
    "        stdout.flush()\n",
    "        \n",
    "    if epoch % 5 == 0:\n",
    "        generated_images = generator.predict(np.random.normal(size=(len(x_fid_test), 100)))\n",
    "        generated_images = tf.convert_to_tensor(generated_images, dtype=tf.float32)\n",
    "\n",
    "        frechet_distance = util.mnist_frechet_distance(x_fid_test, generated_images)\n",
    "        stdout.write(\"\\nFID: %.4f\" % frechet_distance)\n",
    "\n",
    "        save_predicted_images(generator, OUTPUT_DIR, epoch, frechet_distance)\n",
    "\n",
    "        for i in range(len(frechet_distance_checkpoints)):\n",
    "            if frechet_distance <= frechet_distance_checkpoints[i].dist and frechet_distance >= frechet_distance_checkpoints[i + 1].dist:\n",
    "                stdout.write(\"\\n\\nSAVING THE GENERATOR MODEL, FD: %.4f\\n\\n\" % frechet_distance)\n",
    "                save_generator_model(generator, CHECKPOINT_DIR, epoch, frechet_distance)                    \n",
    "\n",
    "        if frechet_distance <= 0.01:\n",
    "            num_of_good_epochs += 1\n",
    "            if num_of_good_epochs >= 4:\n",
    "                break\n",
    "        else:\n",
    "            num_of_good_epochs = 0\n",
    "    stdout.write(\"\\n\")\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GENERATOR LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "plt.plot(np.asarray(generator_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DISCRIMINATOR LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 15))\n",
    "plt.plot(np.asarray([discriminator_loss_elem[-1] for discriminator_loss_elem in discriminator_loss]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_size = 28\n",
    "def plot_digits(*args):\n",
    "    args = [x.squeeze() for x in args]\n",
    "    n = min([x.shape[0] for x in args])\n",
    "    figure = np.zeros((digit_size * len(args), digit_size * n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(len(args)):\n",
    "            figure[j * digit_size: (j + 1) * digit_size,\n",
    "                   i * digit_size: (i + 1) * digit_size] = args[j][i].squeeze()\n",
    "\n",
    "    plt.figure(figsize=(2 * n, 2 * len(args)))\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.grid(False)\n",
    "    ax = plt.gca()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_compare = 10\n",
    "to_compare = []\n",
    "for i in range(n_compare):\n",
    "    codes = np.random.normal(size=(n_compare, 100))\n",
    "    predicted = generator.predict(codes)\n",
    "    to_compare.append(predicted)\n",
    "plot_digits(*to_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
